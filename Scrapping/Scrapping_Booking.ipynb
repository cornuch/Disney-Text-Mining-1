{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Méthode 1 : Récupérer champ par champ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\houde\\AppData\\Local\\Temp\\ipykernel_9288\\1378972995.py:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(\"/usr/local/bin/chromedriver\")\n"
     ]
    }
   ],
   "source": [
    "# Url / set a list of URLS later\n",
    "url = \"https://www.booking.com/hotel/fr/disney-39-s-newport-bay-club-r.fr.html#tab-reviews\"\n",
    "\n",
    "# Get the driver\n",
    "driver = webdriver.Chrome(\"/usr/local/bin/chromedriver\")\n",
    "\n",
    "# Create list to get the data\n",
    "collectName = []\n",
    "collectCountry = []\n",
    "collectType_room = []\n",
    "collectLen_reservation = []\n",
    "collectMonth_year = []\n",
    "collectVoyageur_info = []\n",
    "collectDate_review = []\n",
    "collectReview_title = []\n",
    "collectGrade_review = []\n",
    "collectPositive_review = []\n",
    "collectNegative_review = []\n",
    "collectIs_review_usefull = []\n",
    "\n",
    "chiffres = list(\"0123456789\")\n",
    "\n",
    "# Put the url into the driver\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "# Reject cookies\n",
    "driver.find_element(By.ID, \"onetrust-reject-all-handler\").click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "n_pages = driver.find_element(By.XPATH, '//*[@id=\"review_list_page_container\"]/div[4]/div/div[1]/div/div[2]/div/div[7]/a/span[1]').text\n",
    "n_pages = int(n_pages)\n",
    "\n",
    "for p in range(1,n_pages+1):\n",
    "    \n",
    "    time.sleep(2)\n",
    "\n",
    "    for i in range(1,11):\n",
    "        \n",
    "        time.sleep(1)\n",
    "\n",
    "        name_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[1]/div[1]/div/div[2]/span[1]'\n",
    "        try:\n",
    "            name = driver.find_element(By.XPATH, name_path).text\n",
    "        except:\n",
    "            name = None\n",
    "        collectName.append(name)\n",
    "\n",
    "        country_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[1]/div[1]/div/div[2]/span[2]'\n",
    "        try:\n",
    "            country = driver.find_element(By.XPATH, country_path).text\n",
    "        except:\n",
    "            country = None\n",
    "        collectCountry.append(country)\n",
    "\n",
    "        type_room_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[1]/div[2]/ul/li/a'\n",
    "        \n",
    "        try: \n",
    "            type_room = driver.find_element(By.XPATH, type_room_path).text\n",
    "        except:\n",
    "            type_room = None\n",
    "        collectType_room.append(type_room)\n",
    "\n",
    "        len_reservation_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[1]/ul[1]/li/div'\n",
    "        try:\n",
    "            len_reservation = driver.find_element(By.XPATH, len_reservation_path).text\n",
    "        except:\n",
    "            len_reservation = None\n",
    "        collectLen_reservation.append(len_reservation)\n",
    "\n",
    "        month_year_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[1]/ul[1]/li/div/span'\n",
    "        try:\n",
    "            month_year = driver.find_element(By.XPATH, month_year_path).text\n",
    "        except:\n",
    "            month_year = None\n",
    "        collectMonth_year.append(month_year)\n",
    "\n",
    "        voyageur_info_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[1]/ul[2]/li'\n",
    "        try:\n",
    "            voyageur_info = driver.find_element(By.XPATH, voyageur_info_path).text\n",
    "        except:\n",
    "            voyageur_info = None\n",
    "        collectVoyageur_info.append(voyageur_info)\n",
    "\n",
    "        date_review_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[1]/span'\n",
    "        try:\n",
    "            date_review = driver.find_element(By.XPATH, date_review_path).text\n",
    "        except:\n",
    "            date_review = None\n",
    "        collectDate_review.append(date_review)\n",
    "\n",
    "        review_title_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[1]/div/div[1]/h3'\n",
    "        try:\n",
    "            review_title = driver.find_element(By.XPATH, review_title_path).text\n",
    "        except:\n",
    "            review_title = None\n",
    "        collectReview_title.append(review_title)\n",
    "\n",
    "        grade_review_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[1]/div/div[2]/div/div'\n",
    "        try:\n",
    "            grade_review = driver.find_element(By.XPATH, grade_review_path).text\n",
    "        except:\n",
    "            grade_review = None\n",
    "        collectGrade_review.append(grade_review)\n",
    "\n",
    "        positive_review_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[2]/div/div[1]/p/span[3]'\n",
    "        try:\n",
    "            positive_review = driver.find_element(By.XPATH, positive_review_path).text\n",
    "        except: \n",
    "            positive_review = None\n",
    "        collectPositive_review.append(positive_review)\n",
    "        \n",
    "        negative_review_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[2]/div/div[2]/p/span[3]'\n",
    "        try:\n",
    "            negative_review = driver.find_element(By.XPATH, negative_review_path).text\n",
    "        except:\n",
    "            negative_review = None\n",
    "\n",
    "        collectNegative_review.append(negative_review)\n",
    "\n",
    "        is_review_usefull_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[3]/div/div[1]'\n",
    "        try:\n",
    "            is_review_usefull = driver.find_element(By.XPATH, is_review_usefull_path).text\n",
    "        except:\n",
    "            is_review_usefull = None\n",
    "        collectIs_review_usefull.append(is_review_usefull)\n",
    "        \n",
    "    try:\n",
    "        driver.find_element(By.CLASS_NAME, \"pagenext\").click()     \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Méthode 2 : Récupérer commentaire par commentaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\houde\\AppData\\Local\\Temp\\ipykernel_19636\\3196208583.py:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(\"/usr/lib/chromium-browser/chromedriver\")\n"
     ]
    }
   ],
   "source": [
    "# Url / set a list of URLS later\n",
    "url = \"https://www.booking.com/hotel/fr/disney-39-s-newport-bay-club-r.fr.html#tab-reviews\"\n",
    "\n",
    "# Get the driver\n",
    "driver = webdriver.Chrome(\"/usr/local/bin/chromedriver\")\n",
    "\n",
    "doc_review = []\n",
    "# Put the url into the driver\n",
    "driver.get(url)\n",
    "\n",
    "# Reject cookies\n",
    "driver.find_element(By.ID, \"onetrust-reject-all-handler\").click()\n",
    "\n",
    "chiffres = list(\"0123456789\")\n",
    "n_pages = driver.find_element(By.XPATH, '//*[@id=\"review_list_page_container\"]/div[4]/div/div[1]/div/div[2]/div').text\n",
    "n_pages = n_pages[-5:]\n",
    "n_pages = \"\".join([w for w in n_pages if w in chiffres])\n",
    "n_pages = int(n_pages)\n",
    "\n",
    "for p in range(1,n_pages+1):\n",
    "    time.sleep(2)\n",
    "\n",
    "    for i in range(1,11):\n",
    "        full_review_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']'\n",
    "        try : \n",
    "            review = driver.find_element(By.XPATH,  full_review_path).text\n",
    "        except:\n",
    "            pass\n",
    "        doc_review.append(review)\n",
    "\n",
    "    try:\n",
    "        driver.find_element(By.CLASS_NAME, \"pagenext\").click()  \n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Méthode 3 : Récupérer page par page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url / set a list of URLS later\n",
    "url = \"https://www.booking.com/hotel/fr/disney-39-s-newport-bay-club-r.fr.html#tab-reviews\"\n",
    "\n",
    "# Get the driver\n",
    "driver = webdriver.Chrome(\"/usr/local/bin/chromedriver\")\n",
    "\n",
    "doc_review = []\n",
    "# Put the url into the driver\n",
    "driver.get(url)\n",
    "\n",
    "# Reject cookies\n",
    "driver.find_element(By.ID, \"onetrust-reject-all-handler\").click()\n",
    "\n",
    "chiffres = list(\"0123456789\")\n",
    "n_pages = driver.find_element(By.XPATH, '//*[@id=\"review_list_page_container\"]/div[4]/div/div[1]/div/div[2]/div').text\n",
    "n_pages = n_pages[-5:]\n",
    "n_pages = \"\".join([w for w in n_pages if w in chiffres])\n",
    "n_pages = int(n_pages)\n",
    "\n",
    "for p in range(1,n_pages+1):\n",
    "    time.sleep(2)\n",
    "\n",
    "    full_page_path = '//*[@id=\"review_list_page_container\"]/ul'\n",
    "    try : \n",
    "        review = driver.find_element(By.XPATH,  full_review_path).text\n",
    "    except:\n",
    "        pass\n",
    "    doc_review.append(review)\n",
    "\n",
    "    try:\n",
    "        driver.find_element(By.CLASS_NAME, \"pagenext\").click()  \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stockage du scrapping dans un fichier pickle (car peut exigeant à l'écriture) afin d'ouvrir les données sans avoir à scrapper à chaque fois (12 minutes pour la méthode 2, méthode 1 =  58 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to store list to file using pickle module\n",
    "import pickle\n",
    "\n",
    "# write list to binary file\n",
    "def write_list(a_list):\n",
    "    # store list in binary file so 'wb' mode\n",
    "    with open('collectIs_review_usefull', 'wb') as fp:\n",
    "        pickle.dump(collectIs_review_usefull, fp)\n",
    "        print('Done writing list into a binary file')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporter les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing list into a binary file\n"
     ]
    }
   ],
   "source": [
    "write_list(collectIs_review_usefull)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importer les données sauvegardées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Read list to memory\n",
    "def read_list():\n",
    "    # for reading also binary mode is important\n",
    "    with open('scrapping', 'rb') as fp:\n",
    "        n_list = pickle.load(fp)\n",
    "        return n_list\n",
    "        \n",
    "scrapping = read_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Names = collectName\n",
    "Country = collectCountry\n",
    "room_type = collectType_room\n",
    "reservation_type = collectLen_reservation\n",
    "Duration = collectMonth_year\n",
    "traveler_infos = collectVoyageur_info\n",
    "date_review = collectDate_review\n",
    "review_title = collectReview_title\n",
    "grade_review = collectGrade_review\n",
    "positive_review = collectPositive_review\n",
    "negative_review = collectNegative_review\n",
    "usefulness_review = collectIs_review_usefull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Names', 'Country', 'room_type', 'reservation_type', 'Duration', 'traveler_infos', 'date_review', 'review_title', 'grade_review', 'positive_review', 'negative_review', 'usefulness_review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(Names, Country,room_type, reservation_type, Duration, traveler_infos, date_review, review_title, grade_review, positive_review, negative_review, usefulness_review)), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.assign(hotel=\"Disney's Newport Bay Club\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:\\Users\\houde\\Documents\\GitHub\\Disney-Text-Mining\\Scrapping\\Scrapping_Newport_Bay_Club_071222.csv', index = False, sep=';', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b16b5e40b26fc74d21e921d7f9348a7b0997adadfafa1fa5a2ce7e2f89b5982f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
