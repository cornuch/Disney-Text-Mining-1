{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "import io\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Méthode 1 : Récupérer champ par champ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\houde\\AppData\\Local\\Temp\\ipykernel_16556\\1026010438.py:12: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(\"/usr/local/bin/chromedriver\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.booking.com/hotel/fr/disney-39-s-cheyenne-r.fr.html#tab-reviews\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[141], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m check \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     61\u001b[0m \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,n_pages\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m---> 62\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m2\u001b[39;49m)\n\u001b[0;32m     64\u001b[0m     \u001b[39mif\u001b[39;00m check \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     66\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m11\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Get the driver\n",
    "driver = webdriver.Chrome(\"/usr/local/bin/chromedriver\")\n",
    "\n",
    "HotelsUrls = {'Newport_Bay_Club' : 'https://www.booking.com/hotel/fr/disney-39-s-newport-bay-club-r.fr.html#tab-reviews', 'Cheyenne' : 'https://www.booking.com/hotel/fr/disney-39-s-cheyenne-r.fr.html#tab-reviews', 'Sequoia_Lodge' : 'https://www.booking.com/hotel/fr/disneys-sequoia-lodge-r.fr.html#tab-reviews', 'New_York' : 'https://www.booking.com/hotel/fr/disney-39-s-new-york-r.fr.html#tab-reviews', 'Davy_Crockett_Ranch' : 'https://www.booking.com/hotel/fr/disneys-davy-crockett-ranch.fr.html#tab-reviews', 'Santa_Fe' : 'https://www.booking.com/hotel/fr/disney-39-s-santa-fe-r.fr.html#tab-reviews'}\n",
    "\n",
    "chiffres = list(\"0123456789\")\n",
    "\n",
    "for hotel in range(len(HotelsUrls)) : \n",
    "\n",
    "    # Create list to get the data\n",
    "    collectName = []\n",
    "    collectCountry = []\n",
    "    collectType_room = []\n",
    "    collectLen_reservation = []\n",
    "    collectMonth_year = []\n",
    "    collectVoyageur_info = []\n",
    "    collectDate_review = []\n",
    "    collectReview_title = []\n",
    "    collectGrade_review = []\n",
    "    collectPositive_review = []\n",
    "    collectNegative_review = []\n",
    "    collectIs_review_usefull = []\n",
    "    collectUniqueID = []\n",
    "\n",
    "    git = 'https://github.com/paulineattal/Disney-Text-Mining/blob/main/fichiers/Scrapping_' + str(list(HotelsUrls.keys())[hotel]) + '.csv'\n",
    "    link = git.replace(\"github.com\", \"raw.githubusercontent.com\").replace(\"/blob/\", \"/\")\n",
    "    try : \n",
    "        checkUrl = requests.get(link).content\n",
    "        checkScrapping = pd.read_csv(io.StringIO(checkUrl.decode('utf-8')), sep = ';')\n",
    "    except : \n",
    "        pass \n",
    "\n",
    "    url = HotelsUrls.get(list(HotelsUrls.keys())[hotel])\n",
    "    print(url)\n",
    "\n",
    "    # Put the url into the driver\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(2)\n",
    "    # Reject cookies\n",
    "    driver.find_element(By.ID, \"onetrust-reject-all-handler\").click()\n",
    "\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"review_sort\"]/option[2]').click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    n_pages = driver.find_element(By.XPATH, '//*[@id=\"review_list_page_container\"]/div[4]/div/div[1]/div/div[2]/div/div[7]/a/span[1]').text\n",
    "    n_pages = int(n_pages)\n",
    "\n",
    "    check = 0\n",
    "\n",
    "    for p in range(1,n_pages+1):\n",
    "        time.sleep(2)\n",
    "\n",
    "        if check == 0:\n",
    "\n",
    "            for i in range(1,11):\n",
    "                \n",
    "                time.sleep(1)      \n",
    "                if check == 0 :\n",
    "                    # Nom voyageur\n",
    "                    name_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[1]/div[1]/div/div[2]/span[1]'\n",
    "                    try:\n",
    "                        name = driver.find_element(By.XPATH, name_path).text\n",
    "                    except:\n",
    "                        name = \"empty\"\n",
    "                    collectName.append(name)\n",
    "\n",
    "                    # Pays voyageur\n",
    "                    country_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[1]/div[1]/div/div[2]/span[2]'\n",
    "                    try:\n",
    "                        country = driver.find_element(By.XPATH, country_path).text\n",
    "                    except:\n",
    "                        country = \"empty\"\n",
    "                    collectCountry.append(country)\n",
    "\n",
    "                    # Type de chambre\n",
    "                    type_room_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[1]/div[2]/ul/li/a'\n",
    "        \n",
    "                    try: \n",
    "                        type_room = driver.find_element(By.XPATH, type_room_path).text\n",
    "                    except:\n",
    "                        type_room = \"empty\"\n",
    "                    collectType_room.append(type_room)\n",
    "\n",
    "                    # Nuitées\n",
    "                    len_reservation_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[1]/ul[1]/li/div'\n",
    "                    try:\n",
    "                        len_reservation = driver.find_element(By.XPATH, len_reservation_path).text\n",
    "                    except:\n",
    "                        len_reservation = \"empty\"\n",
    "                    collectLen_reservation.append(len_reservation[0])\n",
    "\n",
    "                    # Mois année du voyage\n",
    "                    month_year_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[1]/ul[1]/li/div/span'\n",
    "                    try:\n",
    "                        month_year = driver.find_element(By.XPATH, month_year_path).text\n",
    "                    except:\n",
    "                        month_year = \"empty\"\n",
    "                    collectMonth_year.append(month_year)\n",
    "\n",
    "                    # Informations voyageur\n",
    "                    voyageur_info_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[1]/ul[2]/li'\n",
    "                    try:\n",
    "                        voyageur_info = driver.find_element(By.XPATH, voyageur_info_path).text\n",
    "                    except:\n",
    "                        voyageur_info = \"empty\"\n",
    "                    collectVoyageur_info.append(voyageur_info)\n",
    "\n",
    "                    # Date \n",
    "                    date_review_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[1]/span'\n",
    "                    date_review_path2 = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[1]/span[2]'\n",
    "\n",
    "                    try:\n",
    "                        date_review = driver.find_element(By.XPATH, date_review_path).text\n",
    "                    except:\n",
    "                        date_review = \"empty\"\n",
    "\n",
    "                    if date_review == 'Le choix des voyageurs' : \n",
    "        \n",
    "                        try:\n",
    "                            date_review = driver.find_element(By.XPATH, date_review_path2).text\n",
    "                        except:\n",
    "                            date_review = \"empty\"\n",
    "                    collectDate_review.append(date_review)\n",
    "\n",
    "                    # Titre commentaire \n",
    "                    review_title_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[1]/div/div[1]/h3'\n",
    "                    try:\n",
    "                        review_title = driver.find_element(By.XPATH, review_title_path).text\n",
    "                    except:\n",
    "                        review_title = \"empty\"\n",
    "                    collectReview_title.append(review_title)\n",
    "        \n",
    "                    # Note\n",
    "                    grade_review_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[1]/div/div[2]/div/div'\n",
    "                    try:\n",
    "                        grade_review = driver.find_element(By.XPATH, grade_review_path).text\n",
    "                    except:\n",
    "                        grade_review = \"empty\"\n",
    "                    collectGrade_review.append(grade_review)\n",
    "\n",
    "                    # Commentaire positif\n",
    "                    positive_review_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[2]/div/div[1]/p/span[3]'\n",
    "                    try:\n",
    "                        positive_review = driver.find_element(By.XPATH, positive_review_path).text\n",
    "                    except: \n",
    "                        positive_review = \"empty\"\n",
    "                    collectPositive_review.append(positive_review)\n",
    "        \n",
    "                    # Commentaire négatif\n",
    "                    negative_review_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[2]/div/div[2]/p/span[3]'\n",
    "                    try:\n",
    "                        negative_review = driver.find_element(By.XPATH, negative_review_path).text\n",
    "                    except:\n",
    "                        negative_review = \"empty\"\n",
    "                    collectNegative_review.append(negative_review)\n",
    "\n",
    "                    # Utilité commentaire\n",
    "                    is_review_usefull_path = '//*[@id=\"review_list_page_container\"]/ul/li['+str(i)+']/div/div[2]/div[2]/div[3]/div/div[1]'\n",
    "                    try:\n",
    "                        is_review_usefull = driver.find_element(By.XPATH, is_review_usefull_path).text\n",
    "                    except:\n",
    "                        is_review_usefull = \"empty\"\n",
    "                    collectIs_review_usefull.append(is_review_usefull)\n",
    "\n",
    "                    UniqueID = name + country + type_room + month_year + voyageur_info + date_review + review_title\n",
    "                    print(UniqueID)\n",
    "                    try: \n",
    "                        check = len(checkScrapping[checkScrapping['UniqueID'] == UniqueID])\n",
    "                    except: \n",
    "                        check = 0\n",
    "                \n",
    "                    print(check)\n",
    "\n",
    "                    collectUniqueID.append(UniqueID)\n",
    "        \n",
    "            # Changer de page    \n",
    "            try:\n",
    "                driver.find_element(By.CLASS_NAME, \"pagenext\").click()     \n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "        else:\n",
    "            break\n",
    "\n",
    "    driver.close()\n",
    "    \n",
    "    Names = collectName\n",
    "    Country = collectCountry\n",
    "    room_type = collectType_room\n",
    "    nuitee = collectLen_reservation\n",
    "    reservation_date = collectMonth_year\n",
    "    traveler_infos = collectVoyageur_info\n",
    "    date_review = collectDate_review\n",
    "    review_title = collectReview_title\n",
    "    grade_review = collectGrade_review\n",
    "    positive_review = collectPositive_review\n",
    "    negative_review = collectNegative_review\n",
    "    usefulness_review = collectIs_review_usefull\n",
    "    UniqueID = collectUniqueID\n",
    "    columns = ['Names', 'Country', 'room_type', 'nuitee', 'reservation_date', 'traveler_infos', 'date_review', 'review_title', 'grade_review', 'positive_review', 'negative_review', 'usefulness_review', 'UniqueID']\n",
    "\n",
    "    df = pd.DataFrame(list(zip(Names, Country,room_type, nuitee, reservation_date, traveler_infos, date_review, review_title, grade_review, positive_review, negative_review, usefulness_review, UniqueID)), columns=columns)\n",
    "    df=df.assign(hotel= str(list(HotelsUrls.keys())[hotel]))\n",
    "\n",
    "    df.loc[(df.usefulness_review == 'Utile Pas utile'),'usefulness_review']='NaN'\n",
    "\n",
    "    df['usefulness_review'] = df['usefulness_review'].str[:2]\n",
    "\n",
    "    for i in range(len(df)): \n",
    "\n",
    "        if df['usefulness_review'][i] == \"em\":\n",
    "            df['usefulness_review'][i] = 0\n",
    "\n",
    "        if df['usefulness_review'][i] is None:\n",
    "            df['usefulness_review'][i] = 0\n",
    "\n",
    "    df.drop_duplicates(keep='first')\n",
    "    print(df)\n",
    "    #df.to_csv(r'C:\\Users\\houde\\Documents\\GitHub\\Disney-Text-Mining\\Scrapping\\Scrapping_' + str(list(HotelsUrls.keys())[i]) + '.csv', index = False, sep=';', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Names = collectName\n",
    "Country = collectCountry\n",
    "room_type = collectType_room\n",
    "nuitee = collectLen_reservation\n",
    "reservation_date = collectMonth_year\n",
    "traveler_infos = collectVoyageur_info\n",
    "date_review = collectDate_review\n",
    "review_title = collectReview_title\n",
    "grade_review = collectGrade_review\n",
    "positive_review = collectPositive_review\n",
    "negative_review = collectNegative_review\n",
    "usefulness_review = collectIs_review_usefull\n",
    "UniqueID = collectUniqueID\n",
    "columns = ['Names', 'Country', 'room_type', 'nuitee', 'reservation_date', 'traveler_infos', 'date_review', 'review_title', 'grade_review', 'positive_review', 'negative_review', 'usefulness_review', 'UniqueID']\n",
    "\n",
    "df = pd.DataFrame(list(zip(Names, Country,room_type, nuitee, reservation_date, traveler_infos, date_review, review_title, grade_review, positive_review, negative_review, usefulness_review, UniqueID)), columns=columns)\n",
    "#df=df.assign(hotel= str(list(HotelsUrls.keys())[i]))\n",
    "\n",
    "df.loc[(df.usefulness_review == 'Utile Pas utile'),'usefulness_review']='NaN'\n",
    "\n",
    "df['usefulness_review'] = df['usefulness_review'].str[:2]\n",
    "\n",
    "for i in range(len(df)): \n",
    "\n",
    "    if df['usefulness_review'][i] == \"em\":\n",
    "        df['usefulness_review'][i] = 0\n",
    "\n",
    "    if df['usefulness_review'][i] is None:\n",
    "        df['usefulness_review'][i] = 0\n",
    "\n",
    "    if df['usefulness_review'][i] is \"Na\":\n",
    "        df['usefulness_review'][i] = 0\n",
    "\n",
    "df.drop_duplicates(keep='first')\n",
    "\n",
    "#df.to_csv(r'C:\\Users\\houde\\Documents\\GitHub\\Disney-Text-Mining\\Scrapping\\Scrapping_' + str(list(HotelsUrls.keys())[i]) + '.csv', index = False, sep=';', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b16b5e40b26fc74d21e921d7f9348a7b0997adadfafa1fa5a2ce7e2f89b5982f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
